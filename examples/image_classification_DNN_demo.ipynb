{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 14006\n",
      "验证集大小: 6003\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据预处理\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "dataset = datasets.ImageFolder(root='/home/ubuntu/IndustrialDigitDatasetGenerator/classification_dataset', transform=data_transforms)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 数据加载器\n",
    "# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f'训练集大小: {train_size}')\n",
    "print(f'验证集大小: {val_size}')\n",
    "\n",
    "# # 打印具体分类的大小\n",
    "# train_class_counts = {class_name: 0 for class_name in dataset.classes}\n",
    "# val_class_counts = {class_name: 0 for class_name in dataset.classes}\n",
    "\n",
    "# for _, label in train_dataset:\n",
    "#     train_class_counts[dataset.classes[label]] += 1\n",
    "\n",
    "# for _, label in val_dataset:\n",
    "#     val_class_counts[dataset.classes[label]] += 1\n",
    "\n",
    "# print(\"训练集分类大小:\")\n",
    "# for class_name, count in train_class_counts.items():\n",
    "#     print(f'{class_name}: {count}')\n",
    "\n",
    "# print(\"验证集分类大小:\")\n",
    "# for class_name, count in val_class_counts.items():\n",
    "#     print(f'{class_name}: {count}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/AnomalyCLIP/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/AnomalyCLIP/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的 ResNet50 模型\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# model = models.resnet18(pretrained=True)\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "# model = models.mnasnet1_0(weights=models.MNASNet1_0_Weights.DEFAULT)\n",
    "# model = models.maxvit_t(weights=models.MaxVit_T_Weights.DEFAULT)\n",
    "\n",
    "# 打印模型的输入向量的大小\n",
    "# print(f\"模型的输入向量大小: {model.fc.in_features}\")\n",
    "\n",
    "# 打印模型的细节\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, val_dataset, num_epochs=10, batch_size=64, learning_rate=0.001, save_interval=2, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        train_loader_tqdm = tqdm(train_loader, desc=\"训练进度\", leave=False)\n",
    "        \n",
    "        for inputs, labels in train_loader_tqdm:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            train_loader_tqdm.set_postfix({'Loss': loss.item()})\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "        print(f'训练损失: {epoch_loss:.4f} 训练准确率: {epoch_acc:.4f}')\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_dataset)\n",
    "        val_acc = val_running_corrects.double() / len(val_dataset)\n",
    "        print(f'验证损失: {val_loss:.4f} 验证准确率: {val_acc:.4f}')\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print('已保存最佳模型：best_model.pth')\n",
    "        \n",
    "        # 每隔 save_interval 轮保存一次模型\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = f'checkpoint_epoch_{epoch+1}.pth'\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'已保存模型到 {checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.6249 训练准确率: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证损失: 0.0413 验证准确率: 0.9872\n",
      "已保存最佳模型：best_model.pth\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.0244 训练准确率: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证损失: 0.0325 验证准确率: 0.9900\n",
      "已保存最佳模型：best_model.pth\n",
      "已保存模型到 checkpoint_epoch_2.pth\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.0160 训练准确率: 0.9941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证损失: 0.0247 验证准确率: 0.9922\n",
      "已保存最佳模型：best_model.pth\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.0132 训练准确率: 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证损失: 0.0293 验证准确率: 0.9920\n",
      "已保存模型到 checkpoint_epoch_4.pth\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.0104 训练准确率: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证损失: 0.0356 验证准确率: 0.9902\n"
     ]
    }
   ],
   "source": [
    "# 修改最后的全连接层\n",
    "if hasattr(model, 'fc'):\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 10)  # 10 类分类\n",
    "elif hasattr(model, 'Linear'):\n",
    "    num_ftrs = model.Linear.in_features\n",
    "    model.Linear = nn.Linear(num_ftrs, 10)  # 10 类分类\n",
    "\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 10)  # 10 类分类\n",
    "\n",
    "train(model, \n",
    "      train_dataset, \n",
    "      val_dataset, \n",
    "      num_epochs=5, \n",
    "      batch_size=256, \n",
    "      learning_rate=0.001, \n",
    "      save_interval=2, \n",
    "      device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "已处理：02.bmp -> 2_02.bmp，处理时间：48.19 ms\n",
      "tensor([7], device='cuda:0')\n",
      "已处理：1 - 副本.bmp -> 7_1 - 副本.bmp，处理时间：9.26 ms\n",
      "tensor([3], device='cuda:0')\n",
      "已处理：num.bmp -> 3_num.bmp，处理时间：9.75 ms\n",
      "tensor([7], device='cuda:0')\n",
      "已处理：17.bmp -> 7_17.bmp，处理时间：9.16 ms\n",
      "tensor([2], device='cuda:0')\n",
      "已处理：11.bmp -> 2_11.bmp，处理时间：8.88 ms\n",
      "tensor([9], device='cuda:0')\n",
      "已处理：09.bmp -> 9_09.bmp，处理时间：9.01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1821510/3676937203.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))  # 加载训练好的模型权重\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8], device='cuda:0')\n",
      "已处理：08.bmp -> 8_08.bmp，处理时间：11.06 ms\n",
      "tensor([7], device='cuda:0')\n",
      "已处理：15_待识别数字_0.jpg -> 7_15_待识别数字_0.jpg，处理时间：9.49 ms\n",
      "tensor([4], device='cuda:0')\n",
      "已处理：04.bmp -> 4_04.bmp，处理时间：13.02 ms\n",
      "tensor([2], device='cuda:0')\n",
      "已处理：1.bmp -> 2_1.bmp，处理时间：9.01 ms\n",
      "tensor([3], device='cuda:0')\n",
      "已处理：33.bmp -> 3_33.bmp，处理时间：13.56 ms\n",
      "tensor([1], device='cuda:0')\n",
      "已处理：11 (2).bmp -> 1_11 (2).bmp，处理时间：9.32 ms\n",
      "tensor([1], device='cuda:0')\n",
      "已处理：01.bmp -> 1_01.bmp，处理时间：9.30 ms\n",
      "tensor([2], device='cuda:0')\n",
      "已处理：2.jpg -> 2_2.jpg，处理时间：11.41 ms\n",
      "tensor([0], device='cuda:0')\n",
      "已处理：10.bmp -> 0_10.bmp，处理时间：9.03 ms\n",
      "tensor([2], device='cuda:0')\n",
      "已处理：12.bmp -> 2_12.bmp，处理时间：9.43 ms\n",
      "tensor([5], device='cuda:0')\n",
      "已处理：process12000.png -> 5_process12000.png，处理时间：11.62 ms\n",
      "tensor([4], device='cuda:0')\n",
      "已处理：10 - 副本.bmp -> 4_10 - 副本.bmp，处理时间：10.03 ms\n",
      "tensor([2], device='cuda:0')\n",
      "已处理：15_待识别数字_1.jpg -> 2_15_待识别数字_1.jpg，处理时间：9.51 ms\n",
      "tensor([9], device='cuda:0')\n",
      "已处理：9.jpg -> 9_9.jpg，处理时间：9.11 ms\n",
      "tensor([1], device='cuda:0')\n",
      "已处理：11 (3).bmp -> 1_11 (3).bmp，处理时间：9.33 ms\n",
      "tensor([6], device='cuda:0')\n",
      "已处理：6.jpg -> 6_6.jpg，处理时间：10.41 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型\n",
    "model.load_state_dict(torch.load('best_model.pth'))  # 加载训练好的模型权重\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "# 数据预处理（与训练时相同）\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "# 类别名称列表（根据你的实际类别名称修改）\n",
    "class_names = ['0', '1', '2', '3', '4','5', '6', '7', '8', '9']\n",
    "# 测试图像文件夹路径\n",
    "test_dir = '/home/ubuntu/IndustrialDigitDatasetGenerator/sigle_num'  # 替换为你的测试图像文件夹路径\n",
    "# 结果保存文件夹路径\n",
    "output_dir = '/home/ubuntu/IndustrialDigitDatasetGenerator/sigle_num_result'  # 替换为你想要保存预测结果的文件夹路径\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_name in os.listdir(test_dir):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        # 打开图像并预处理\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = data_transforms(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # 开始计时\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 模型预测\n",
    "        outputs = model(input_tensor)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        print(preds)\n",
    "        predicted_class = class_names[preds.item()]\n",
    "        \n",
    "        # 结束计时\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        # 新的文件名，包含预测结果\n",
    "        new_filename = f\"{predicted_class}_{img_name}\"\n",
    "        output_path = os.path.join(output_dir, new_filename)\n",
    "        \n",
    "        # 将图像复制到结果文件夹，并重命名\n",
    "        shutil.copy(img_path, output_path)\n",
    "        \n",
    "        print(f\"已处理：{img_name} -> {new_filename}，处理时间：{processing_time*1000:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1821510/519498139.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始模型评估...\n",
      "\n",
      "分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        32\n",
      "           1       0.79      1.00      0.88        78\n",
      "           2       1.00      0.94      0.97        36\n",
      "           3       1.00      0.78      0.88        36\n",
      "           4       1.00      0.79      0.88        29\n",
      "           5       1.00      0.97      0.98        30\n",
      "           6       1.00      1.00      1.00        18\n",
      "           7       0.93      0.81      0.87        16\n",
      "           8       1.00      0.85      0.92        13\n",
      "           9       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.92       298\n",
      "   macro avg       0.97      0.91      0.93       298\n",
      "weighted avg       0.93      0.92      0.92       298\n",
      "\n",
      "评估完成！结果保存在: /home/ubuntu/IndustrialDigitDatasetGenerator/\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import model_evaluation\n",
    "\n",
    "# 重新加载模块\n",
    "importlib.reload(model_evaluation)\n",
    "\n",
    "# 重新导入 ModelEvaluator 类\n",
    "from model_evaluation import ModelEvaluator\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型（需要你的模型定义）\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# 类别名称\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# 路径设置\n",
    "test_dir = '/home/ubuntu/IndustrialDigitDatasetGenerator/classification_dataset_test'\n",
    "output_dir = '/home/ubuntu/IndustrialDigitDatasetGenerator/'\n",
    "\n",
    "# 创建评估器\n",
    "evaluator = ModelEvaluator(model, device, class_names, test_dir, output_dir)\n",
    "\n",
    "# 运行评估\n",
    "print(\"开始模型评估...\")\n",
    "evaluator.evaluate_model()\n",
    "\n",
    "# 生成混淆矩阵\n",
    "# print(\"生成混淆矩阵...\")\n",
    "evaluator.plot_confusion_matrix()\n",
    "\n",
    "# 打印分类报告\n",
    "evaluator.print_classification_report()\n",
    "\n",
    "# 生成示例图片网格\n",
    "# print(\"生成示例图片...\")\n",
    "success_grid = evaluator.create_example_grid(evaluator.success_examples, True)\n",
    "failed_grid = evaluator.create_example_grid(evaluator.failed_examples, False)\n",
    "\n",
    "import cv2\n",
    "if success_grid is not None:\n",
    "    cv2.imwrite(os.path.join(output_dir, 'success_examples.png'), \n",
    "                cv2.cvtColor(success_grid, cv2.COLOR_RGB2BGR))\n",
    "if failed_grid is not None:\n",
    "    cv2.imwrite(os.path.join(output_dir, 'failed_examples.png'), \n",
    "                cv2.cvtColor(failed_grid, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"评估完成！结果保存在: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
